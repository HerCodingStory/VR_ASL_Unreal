# VR_ASL_Unreal

### ASL: American Sign Language Training System with Gesture Recognition

A Virtual and augmented reality is becoming pervasive in our day to day lives. One particularly important application is Training. We (Research Assistant Students) are developing an American Sign Language training system with gesture recognition using the HTC Vive head-mounted displays(HMD). We are using the Leap Motion 3D Motion Controller in this project to capture the gestures. We expect the first phase to handle the alphabet (static gestures) and in the next phase handle dynamic gestures.

## Getting Started

https://github.com/OpenHID/VRASL2019

### Prerequisites

```
Windows 7 64-bit or higher
HTC Vive
Unreal Engine 4 (4.21.1)
Microsoft Visual Studios 2017 (Version 15.9.5)
Leap Motion SDK Orion 4.0+
Leap Motion Unreal Plugin V 3.2.0
```
## Authors
* **Senior Project Spring 2019**
* **Joseph Medina** - *GitHub* - [JosephMedinaGit](https://github.com/JosephMedinaGit)
* **Lucio Salazar** - *GitHub* - [AceMuska](https://github.com/AceMuska)
* **Jason Garcia** - *GitHub* - [jsg1101](https://github.com/jsg1101)
* **Ciana Rogers** - *GitHub* - [cianarogers](https://github.com/cianarogers)
* **Andy Pujol** - *GitHub* - [apujol09](https://github.com/apujol09)
* **NUI Lab Students, (Formerly known as OpenHID)**
* **Cristina Villaroel** - *GitHub* - [Cristyevr94](https://github.com/Cristyevr94)

## Acknowledgments

* https://github.com/getnamo/leap-ue4
* https://github.com/Victorma/SignAdventure
* https://github.com/leapmotion/LeapUnrealModules
* https://github.com/leapmotion/LeapUnreal 
